{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import pdb\n",
    "%matplotlib inline\n",
    "\n",
    "tfe.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../datasets/MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting ../datasets/MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting ../datasets/MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ../datasets/MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('../datasets/MNIST_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "sample_img = mnist.train.images[3]\n",
    "plt.imshow(sample_img.reshape([28, 28]))\n",
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "class RBM:\n",
    "    def __init__(self, visible_dim, hidden_dim, k=1):\n",
    "        self.visible_dim = visible_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.k = k\n",
    "        \n",
    "        # initiating weight variables\n",
    "        self.W = tf.Variable(np.random.normal(loc=0., scale=0.1, size=(visible_dim, hidden_dim)), dtype=tf.float32)\n",
    "        self.c = tf.Variable(np.ones((visible_dim, 1)), dtype=tf.float32)\n",
    "        self.b = tf.Variable(np.ones((hidden_dim, 1)), dtype=tf.float32) \n",
    "    \n",
    "    \n",
    "    def _energy(self, x, h):\n",
    "        e = tf.matmul(tf.matmul(x, self.W), tf.transpose(h))\n",
    "        e = tf.diag_part(e) + tf.matmul(x, self.c) + tf.matmul(h, self.b)\n",
    "        e = e / tf.cast(tf.shape(x)[0], dtype=tf.float32)\n",
    "        return -1 * e\n",
    "    \n",
    "    \n",
    "    def _prob_of_h_given_x(self, x):\n",
    "        \"\"\"\n",
    "        Input shape\n",
    "            x:  N * V\n",
    "        \"\"\"\n",
    "        \n",
    "        tensor_x = tf.convert_to_tensor(x, dtype=tf.float32)\n",
    "        return tf.sigmoid(tf.matmul(tensor_x, self.W) + tf.transpose(self.b))  \n",
    "    \n",
    "    \n",
    "    def _prob_of_x_given_h(self, h):\n",
    "        \"\"\"\n",
    "        Input shape\n",
    "            h:  N * H\n",
    "        \"\"\"\n",
    "        \n",
    "        tensor_h = tf.convert_to_tensor(h, dtype=tf.float32)\n",
    "        return tf.sigmoid(tf.matmul(tensor_h, tf.transpose(self.W)) + tf.transpose(self.c))    \n",
    "    \n",
    "    \n",
    "    def _sample_from_dist(self, dist):\n",
    "        sample = tf.random.uniform(minval=0, maxval=1, shape=dist.shape)\n",
    "        return tf.cast((dist > sample), dtype=tf.float32)\n",
    "    \n",
    "    \n",
    "    def gibbs_sampler(self, x, Sample=True, return_prob=True):\n",
    "        x_tilde = x\n",
    "        \n",
    "        for _ in range(self.k):\n",
    "            h_dist = self._prob_of_h_given_x(x_tilde)\n",
    "            if Sample:\n",
    "                h = self._sample_from_dist(h_dist)\n",
    "            else:\n",
    "                h = h_dist\n",
    "            \n",
    "            x_dist = self._prob_of_x_given_h(h)\n",
    "            if Sample:\n",
    "                x_tilde = self._sample_from_dist(x_dist)\n",
    "            else:\n",
    "                x_tilde = x_dist\n",
    "        \n",
    "        if return_prob:\n",
    "            return x_dist\n",
    "        else:\n",
    "            return self._sample_from_dist(x_dist)\n",
    "    \n",
    "    \n",
    "    def update_weights(self, x, learning_rate=0.01):\n",
    "        x = tf.convert_to_tensor(x, dtype=tf.float32)\n",
    "        batch_size = tf.cast(tf.shape(x)[0], dtype=tf.float32)\n",
    "        \n",
    "        x_tilde = self.gibbs_sampler(x)\n",
    "        h_tilde_of_x = self._prob_of_h_given_x(x)\n",
    "        h_tilde_of_x_tilde = self._prob_of_h_given_x(x_tilde)\n",
    "        \n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            possitive_energy = self._energy(x, h_tilde_of_x)\n",
    "            negative_energy = self._energy(x, h_tilde_of_x_tilde)\n",
    "        \n",
    "        grad_W = (tape.gradient(possitive_energy, self.W) - tape.gradient(negative_energy, self.W)) / batch_size\n",
    "        grad_c = (tape.gradient(possitive_energy, self.c) - tape.gradient(negative_energy, self.c)) / batch_size\n",
    "        grad_b = (tape.gradient(possitive_energy, self.b) - tape.gradient(negative_energy, self.b)) / batch_size\n",
    "        \n",
    "        grad_E_h_tilde_given_x = tf.matmul(tf.transpose(x), h_tilde_of_x)\n",
    "        grad_E_h_tilde_given_x_tilde = tf.matmul(tf.transpose(x), h_tilde_of_x_tilde)\n",
    "        \n",
    "        grad_W_v2 = (grad_E_h_tilde_given_x - grad_E_h_tilde_given_x_tilde) / batch_size\n",
    "        grad_b_v2 = tf.reduce_sum((h_tilde_of_x - h_tilde_of_x_tilde), axis=0) / batch_size\n",
    "        grad_c_v2 = tf.reduce_sum((x - x_tilde), axis=0) / batch_size   \n",
    "        \n",
    "        pdb.set_trace()\n",
    "        \n",
    "        self.W.assign_add(learning_rate * grad_W_v2)\n",
    "        self.c.assign_add(learning_rate * grad_c_v2)\n",
    "        self.b.assign_add(learning_rate * grad_b_v2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_loss(y, output):\n",
    "    loss = -1. * ((y * np.log(output)) + ((1. - y) * (np.log(1. - output))))\n",
    "    return np.sum(loss) / y.shape[0]\n",
    "\n",
    "\n",
    "epoch = 20\n",
    "batch_size = 200\n",
    "max_iter = int(mnist.train.num_examples/batch_size)\n",
    "print_every = 100\n",
    "cross_entropy = binary_cross_entropy()\n",
    "\n",
    "rbm = RBM(784, 200)\n",
    "\n",
    "for e in range(epoch):\n",
    "    for it in range(max_iter):\n",
    "        batch_x, _ = mnist.train.next_batch(batch_size)\n",
    "        rbm.update_weights(batch_x)\n",
    "    \n",
    "    train_index = np.random.choice(mnist.train.images.shape[0], batch_size)\n",
    "    train_x = mnist.train.images[train_index]\n",
    "    train_sample = rbm.gibbs_sampler(train_x)\n",
    "\n",
    "    train_loss = get_loss(train_x, train_sample)\n",
    "    train_loss = tf.reduce_mean(train_loss)\n",
    "    print(f\"the loss is {train_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "import numpy as np\n",
    "\n",
    "tfe.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_softmax_loss(x, y, mask, verbose=False):\n",
    "    N, T, V = x.get_shape().as_list()\n",
    "\n",
    "    x_flat = tf.reshape(x, [N * T, V]) # x.reshape(N * T, V)\n",
    "    y_flat = tf.reshape(y, [N * T]) # y.reshape(N * T)\n",
    "    mask_flat = tf.reshape(mask, [N * T]) # mask.reshape(N * T)\n",
    "    mask_flat = tf.cast(mask_flat, dtype=tf.float32)\n",
    "\n",
    "    probs = tf.exp(x_flat - tf.reduce_max(x_flat, axis=1, keepdims=True))\n",
    "    probs /= tf.reduce_sum(probs, axis=1, keepdims=True)\n",
    "    probs = tf.gather_nd(probs, tf.stack((tf.range(N * T), y_flat), -1))\n",
    "    loss = -tf.reduce_sum(mask_flat * tf.log(probs)) / N\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "class CaptioningRNN(object):\n",
    "    def __init__(self, word_to_idx, input_dim=512, hidden_dim=128, wordvec_dim=128):\n",
    "        self.word_to_idx = word_to_idx\n",
    "        self.idx_to_word = {i: w for w, i in word_to_idx.items()}\n",
    "        vocab_size = len(word_to_idx)\n",
    "        \n",
    "        self._null = word_to_idx['<NULL>']\n",
    "        self._start = word_to_idx.get('<START>', None)\n",
    "        self._end = word_to_idx.get('<END>', None)\n",
    "        \n",
    "        # initialize layers\n",
    "        initializer = tf.variance_scaling_initializer(scale=2.0)\n",
    "        self.w_embed = tfe.Variable(np.random.randn(vocab_size, wordvec_dim), dtype=tf.float32)\n",
    "        self.proj_layer = tf.layers.Dense(units=hidden_dim, kernel_initializer=initializer)\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "#         self.encoder_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units=hidden_dim)\n",
    "        self.encoder_cell = tf.keras.layers.LSTMCell(units=hidden_dim)\n",
    "        \n",
    "        self.vocab_layer = tf.layers.Dense(units=vocab_size, kernel_initializer=initializer)\n",
    "    \n",
    "    \n",
    "    def get_loss(self, features, captions):\n",
    "        features = tf.convert_to_tensor(features, dtype=tf.float32)\n",
    "        captions_in = tf.convert_to_tensor(captions[:, :-1], dtype=tf.int32)\n",
    "        captions_out = tf.convert_to_tensor(captions[:, 1:], dtype=tf.int32)\n",
    "        mask = tf.not_equal(captions_out, self._null)\n",
    "        \n",
    "        h0 = self.proj_layer(features)\n",
    "        x = tf.nn.embedding_lookup(self.w_embed, captions_in)\n",
    "        \n",
    "        state = tf.nn.rnn_cell.LSTMStateTuple(c=np.zeros((features.shape[0].value, self.hidden_dim)), h=h0)\n",
    "        timestep_x = tf.unstack(x, axis=1)\n",
    "        outputs, cell_states = [], []\n",
    "        \n",
    "#         print(\"features shape: {}\".format(features.shape))\n",
    "#         print(\"captions_in shape: {}\".format(captions_in.shape))\n",
    "#         print(\"h0 shape: {}\".format(h0.shape))\n",
    "#         print(\"timestep_x shape: {}\".format(timestep_x[0].shape))\n",
    "#         print(\"x shape: {}\".format(x.shape))\n",
    "        \n",
    "        for input_step in timestep_x:\n",
    "#             print('input_step shape is {}'.format(input_step.shape))\n",
    "            output, state = self.encoder_cell(input_step, state)\n",
    "            \n",
    "            outputs.append(output)\n",
    "            cell_states.append(state[0])\n",
    "        \n",
    "        outputs = tf.stack(outputs, axis=1)\n",
    "        cell_states = tf.stack(cell_states, axis=1)\n",
    "        \n",
    "        scores = self.vocab_layer(outputs)\n",
    "        loss = temporal_softmax_loss(scores, captions_out, mask)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def sample(self, features, max_length=30):\n",
    "        N = features.shape[0]\n",
    "        captions = self._null * np.ones((N, max_length))\n",
    "        captions = captions.astype(np.int32)\n",
    "        \n",
    "        \n",
    "        h0 = self.proj_layer(features)\n",
    "        x = tf.nn.embedding_lookup(self.w_embed, self._start * np.ones(N, dtype=np.int32))\n",
    "        state = tf.nn.rnn_cell.LSTMStateTuple(c=np.zeros((N, self.hidden_dim)), h=h0)\n",
    "        \n",
    "#         print(\"caption type: {}\".format(captions.dtype))\n",
    "#         print(\"features shape: {}\".format(features.shape))\n",
    "#         print(\"h0 shape: {}\".format(h0.shape))\n",
    "#         print(\"x shape: {}\".format(x.shape))\n",
    "        \n",
    "        for t in range(max_length):\n",
    "            output, state = self.encoder_cell(x, state)\n",
    "            scores = self.vocab_layer(output)\n",
    "            \n",
    "#             print(\"argmax type: {}\".format(tf.argmax(scores, axis=1).dtype))\n",
    "#             print(\"caption type: {}\".format(captions[:, t].dtype))\n",
    "            \n",
    "            captions[:, t] += tf.cast(tf.argmax(scores, axis=1), tf.int32)\n",
    "            x = tf.nn.embedding_lookup(self.w_embed, captions[:, t])\n",
    "        \n",
    "        return captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute '_dims'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-24ca0bfb87c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# encoder.loss(features, captions)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m50\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(self, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name, grad_loss)\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[0maggregation_method\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maggregation_method\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m         grad_loss=grad_loss)\n\u001b[0m\u001b[0;32m    401\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m     \u001b[0mvars_with_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mg\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\u001b[0m in \u001b[0;36mcompute_gradients\u001b[1;34m(self, loss, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, grad_loss)\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvar_list\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m           \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 459\u001b[1;33m         \u001b[0mloss_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m         \u001b[1;31m# Scale loss if using a \"mean\" loss reduction and multiple towers.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-24ca0bfb87c3>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# encoder.loss(features, captions)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m50\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-004ce1ee2014>\u001b[0m in \u001b[0;36mget_loss\u001b[1;34m(self, features, captions)\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0minput_step\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtimestep_x\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;31m#             print('input_step shape is {}'.format(input_step.shape))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m             \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder_cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    755\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0min_deferred_mode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_call\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 757\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    758\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_call\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, states, training)\u001b[0m\n\u001b[0;32m   2016\u001b[0m         \u001b[0mh_tm1_o\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh_tm1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2017\u001b[0m       i = self.recurrent_activation(\n\u001b[1;32m-> 2018\u001b[1;33m           x_i + K.dot(h_tm1_i, self.recurrent_kernel[:, :self.units]))\n\u001b[0m\u001b[0;32m   2019\u001b[0m       f = self.recurrent_activation(\n\u001b[0;32m   2020\u001b[0m           x_f + K.dot(h_tm1_f,\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mdot\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1405\u001b[0m   \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1406\u001b[0m   \"\"\"\n\u001b[1;32m-> 1407\u001b[1;33m   \u001b[1;32mif\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1408\u001b[0m     \u001b[0mx_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mndim\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    948\u001b[0m   \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m   \"\"\"\n\u001b[1;32m--> 950\u001b[1;33m   \u001b[0mdims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    951\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mdims\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute '_dims'"
     ]
    }
   ],
   "source": [
    "N, D, W, H = 10, 20, 30, 40\n",
    "word_to_idx = {'<NULL>': 0, 'cat': 2, 'dog': 3, '<START>': 4, '<END>': 5}\n",
    "V = len(word_to_idx)\n",
    "T = 13\n",
    "\n",
    "features = np.linspace(-0.5, 1.7, num=N*D).reshape(N, D)\n",
    "captions = (np.arange(N * T) % V).reshape(N, T).astype(np.int32)\n",
    "\n",
    "model = CaptioningRNN(word_to_idx, input_dim=D, hidden_dim=H, wordvec_dim=W)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(5e-3)\n",
    "# encoder.loss(features, captions)\n",
    "for e in range(500):\n",
    "    optimizer.minimize(lambda: model.get_loss(features, captions))\n",
    "    \n",
    "    if e % 50 == 0:\n",
    "        l = model.get_loss(features, captions)\n",
    "        print(\"loss {}\".format(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4, 4, 1, 2, 3, 4, 1, 2, 3, 4, 4, 1, 2, 3, 4, 1, 2, 3, 4,\n",
       "        4, 1, 2, 3, 4, 1, 2, 3],\n",
       "       [1, 2, 3, 4, 4, 1, 2, 3, 4, 1, 2, 3, 4, 4, 1, 2, 3, 4, 1, 2, 3, 4,\n",
       "        4, 1, 2, 3, 4, 1, 2, 3],\n",
       "       [1, 2, 3, 4, 4, 1, 2, 3, 4, 1, 2, 3, 4, 4, 1, 2, 3, 4, 1, 2, 3, 4,\n",
       "        4, 1, 2, 3, 4, 1, 2, 3],\n",
       "       [1, 2, 3, 4, 4, 1, 2, 3, 4, 1, 2, 3, 4, 4, 1, 2, 3, 4, 1, 2, 3, 4,\n",
       "        4, 1, 2, 3, 4, 1, 2, 3],\n",
       "       [1, 2, 3, 4, 4, 1, 2, 3, 4, 1, 2, 3, 4, 4, 1, 2, 3, 4, 1, 2, 3, 4,\n",
       "        4, 1, 2, 3, 4, 1, 2, 3],\n",
       "       [1, 2, 3, 4, 4, 1, 2, 3, 4, 1, 2, 3, 4, 4, 1, 2, 3, 4, 1, 2, 3, 4,\n",
       "        4, 1, 2, 3, 4, 1, 2, 3],\n",
       "       [1, 2, 3, 4, 4, 1, 2, 3, 4, 1, 2, 3, 4, 4, 1, 2, 3, 4, 1, 2, 3, 4,\n",
       "        4, 1, 2, 3, 4, 1, 2, 3],\n",
       "       [1, 2, 3, 4, 4, 1, 2, 3, 4, 1, 2, 3, 4, 4, 1, 2, 3, 4, 1, 2, 3, 4,\n",
       "        4, 1, 2, 3, 4, 1, 2, 3],\n",
       "       [1, 2, 3, 4, 4, 1, 2, 3, 4, 1, 2, 3, 4, 4, 1, 2, 3, 4, 1, 2, 3, 4,\n",
       "        4, 1, 2, 3, 4, 1, 2, 3],\n",
       "       [1, 2, 3, 4, 4, 1, 2, 3, 4, 1, 2, 3, 4, 4, 1, 2, 3, 4, 1, 2, 3, 4,\n",
       "        4, 1, 2, 3, 4, 1, 2, 3]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.sample(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "import numpy as np\n",
    "\n",
    "tfe.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_softmax_loss(x, y, mask, verbose=False):\n",
    "    N, T, V = x.get_shape().as_list()\n",
    "\n",
    "    x_flat = tf.reshape(x, [N * T, V]) # x.reshape(N * T, V)\n",
    "    y_flat = tf.reshape(y, [N * T]) # y.reshape(N * T)\n",
    "    mask_flat = tf.reshape(mask, [N * T]) # mask.reshape(N * T)\n",
    "    mask_flat = tf.cast(mask_flat, dtype=tf.float32)\n",
    "\n",
    "    probs = tf.exp(x_flat - tf.reduce_max(x_flat, axis=1, keepdims=True))\n",
    "    probs /= tf.reduce_sum(probs, axis=1, keepdims=True)\n",
    "    probs = tf.gather_nd(probs, tf.stack((tf.range(N * T), y_flat), -1))\n",
    "    loss = -tf.reduce_sum(mask_flat * tf.log(probs)) / N\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "class CaptioningRNN(object):\n",
    "    def __init__(self, word_to_idx, hidden_dim=128, wordvec_dim=128):\n",
    "        self.word_to_idx = word_to_idx\n",
    "        self.idx_to_word = {i: w for w, i in word_to_idx.items()}\n",
    "        vocab_size = len(word_to_idx)\n",
    "        \n",
    "        self._null = word_to_idx['<NULL>']\n",
    "        self._start = word_to_idx.get('<START>', None)\n",
    "        self._end = word_to_idx.get('<END>', None)\n",
    "        \n",
    "        # initialize layers\n",
    "        initializer = tf.variance_scaling_initializer(scale=2.0)\n",
    "        self.w_embed = tfe.Variable(np.random.randn(vocab_size, wordvec_dim), dtype=tf.float32)\n",
    "        self.proj_layer = tf.layers.Dense(units=hidden_dim, kernel_initializer=initializer)\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.encoder_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units=hidden_dim)\n",
    "#         self.encoder_cell = tf.keras.layers.LSTMCell(units=hidden_dim)\n",
    "        \n",
    "        self.vocab_layer = tf.layers.Dense(units=vocab_size, kernel_initializer=initializer)\n",
    "    \n",
    "    \n",
    "    def get_loss(self, features, captions):\n",
    "        features = tf.convert_to_tensor(features, dtype=tf.float32)\n",
    "        captions_in = tf.convert_to_tensor(captions[:, :-1], dtype=tf.int32)\n",
    "        captions_out = tf.convert_to_tensor(captions[:, 1:], dtype=tf.int32)\n",
    "        mask = tf.not_equal(captions_out, self._null)\n",
    "        \n",
    "        h0 = self.proj_layer(features)\n",
    "        x = tf.nn.embedding_lookup(self.w_embed, captions_in)\n",
    "        \n",
    "        state = tf.nn.rnn_cell.LSTMStateTuple(c=np.zeros((features.shape[0].value, self.hidden_dim)), h=h0)\n",
    "        timestep_x = tf.unstack(x, axis=1)\n",
    "        outputs, cell_states = [], []\n",
    "        \n",
    "#         print(\"features shape: {}\".format(features.shape))\n",
    "#         print(\"captions_in shape: {}\".format(captions_in.shape))\n",
    "#         print(\"h0 shape: {}\".format(h0.shape))\n",
    "#         print(\"timestep_x shape: {}\".format(timestep_x[0].shape))\n",
    "#         print(\"x shape: {}\".format(x.shape))\n",
    "        \n",
    "        for input_step in timestep_x:\n",
    "#             print('input_step shape is {}'.format(input_step.shape))\n",
    "            output, state = self.encoder_cell(input_step, state)\n",
    "            \n",
    "            outputs.append(output)\n",
    "            cell_states.append(state[0])\n",
    "        \n",
    "        outputs = tf.stack(outputs, axis=1)\n",
    "        cell_states = tf.stack(cell_states, axis=1)\n",
    "        \n",
    "        scores = self.vocab_layer(outputs)\n",
    "        loss = temporal_softmax_loss(scores, captions_out, mask)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def sample(self, features, max_length=30):\n",
    "        N = features.shape[0]\n",
    "        captions = self._null * np.ones((N, max_length))\n",
    "        captions = captions.astype(np.int32)\n",
    "        \n",
    "        \n",
    "        h0 = self.proj_layer(features)\n",
    "        x = tf.nn.embedding_lookup(self.w_embed, self._start * np.ones(N, dtype=np.int32))\n",
    "        state = tf.nn.rnn_cell.LSTMStateTuple(c=np.zeros((N, self.hidden_dim)), h=h0)\n",
    "        \n",
    "#         print(\"caption type: {}\".format(captions.dtype))\n",
    "#         print(\"features shape: {}\".format(features.shape))\n",
    "#         print(\"h0 shape: {}\".format(h0.shape))\n",
    "#         print(\"x shape: {}\".format(x.shape))\n",
    "        \n",
    "        for t in range(max_length):\n",
    "            output, state = self.encoder_cell(x, state)\n",
    "            scores = self.vocab_layer(output)\n",
    "            \n",
    "#             print(\"argmax type: {}\".format(tf.argmax(scores, axis=1).dtype))\n",
    "#             print(\"caption type: {}\".format(captions[:, t].dtype))\n",
    "            \n",
    "            captions[:, t] += tf.cast(tf.argmax(scores, axis=1), tf.int32)\n",
    "            x = tf.nn.embedding_lookup(self.w_embed, captions[:, t])\n",
    "        \n",
    "        return captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-316a1b1b55da>:33: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000000000FAA5940>: Note that this cell is not optimized for performance. Please use tf.contrib.cudnn_rnn.CudnnLSTM for better performance on GPU.\n",
      "loss 14.411775588989258\n",
      "loss 6.395439147949219\n",
      "loss 2.9432342052459717\n",
      "loss 1.5759485960006714\n",
      "loss 0.9916241765022278\n",
      "loss 0.6958798766136169\n",
      "loss 0.5248154401779175\n",
      "loss 0.41589289903640747\n",
      "loss 0.3415193557739258\n",
      "loss 0.2880096733570099\n"
     ]
    }
   ],
   "source": [
    "N, D, W, H = 10, 20, 30, 40\n",
    "word_to_idx = {'<NULL>': 0, 'cat': 2, 'dog': 3, '<START>': 4, '<END>': 5}\n",
    "V = len(word_to_idx)\n",
    "T = 13\n",
    "\n",
    "features = np.linspace(-0.5, 1.7, num=N*D).reshape(N, D)\n",
    "captions = (np.arange(N * T) % V).reshape(N, T).astype(np.int32)\n",
    "\n",
    "model = CaptioningRNN(word_to_idx, hidden_dim=H, wordvec_dim=W)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(5e-3)\n",
    "# encoder.loss(features, captions)\n",
    "for e in range(500):\n",
    "    optimizer.minimize(lambda: model.get_loss(features, captions))\n",
    "    \n",
    "    if e % 50 == 0:\n",
    "        l = model.get_loss(features, captions)\n",
    "        print(\"loss {}\".format(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 30)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.sample(features).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
